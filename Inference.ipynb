{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a34dd31-7010-4251-bfaa-07c02fdff842",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dc761e2-6990-4eab-ba44-597d7af441d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "import spacy\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from keybert import KeyBERT\n",
    "import openai\n",
    "import ast\n",
    "import re\n",
    "\n",
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66be54d5-a5d9-41f7-b64b-58d2c76e42bb",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "9e15d058-40dc-47cf-8e5f-6154d5e58fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read the API key from a text file\n",
    "def load_api_key(file_path='api_key.txt'):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return file.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5d58b26-84d7-44a9-93ae-9a721128ef31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_list_from_response(response_content):\n",
    "    \"\"\"\n",
    "    This helper function processes the response content to extract the actual Python list.\n",
    "    It removes any extraneous backticks and code block markers, and then safely evaluates\n",
    "    the content to return the list.\n",
    "    \"\"\"\n",
    "    # Remove code block markers and extraneous characters\n",
    "    cleaned_content = [line for line in response_content.splitlines() if line.startswith('[') and line.endswith(']')]\n",
    "    \n",
    "    if cleaned_content:\n",
    "        try:\n",
    "            # Safely evaluate the cleaned content as a Python list\n",
    "            return ast.literal_eval(cleaned_content[0])\n",
    "        except (SyntaxError, ValueError):\n",
    "            return []\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "67077627-58f6-4229-a055-e1ec7f2dea24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract and filter model names using a two-prompt approach\n",
    "def extract_and_filter_model_names(description, api_key):\n",
    "    openai.api_key = api_key\n",
    "\n",
    "    if pd.isna(description):\n",
    "        return []\n",
    "\n",
    "    extraction_prompt = f\"\"\"\n",
    "    Extract only the names of machine learning and deep learning models mentioned in the following solution description, keeping only the names that are used as part of the final solution. List all names in their original format. Do not change the format (if the model name is abbreviated keep it that way, letter case, etc.). Return only a Python list with the names. Do not include any additional text.\n",
    "\n",
    "    Solution Description:\n",
    "    {description}\n",
    "    \"\"\"\n",
    "\n",
    "    # Use the chat completions endpoint for chat models like \"gpt-4o\"\n",
    "    extraction_response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": extraction_prompt}\n",
    "        ]\n",
    "    )\n",
    "    extracted_names = extract_list_from_response(extraction_response.choices[0].message.content)\n",
    "    \n",
    "    if not extracted_names or all(name.strip() == '' for name in extracted_names):\n",
    "        return []\n",
    "\n",
    "    filtering_prompt = f\"\"\"\n",
    "    From the extracted list of names, exclude:\n",
    "    1. Terms related to pooling, activation functions, normalization, and operations.\n",
    "    2. Dataset names and hyperlinks.\n",
    "    3. Duplicates, ensuring each model/method name appears only once.\n",
    "    4. Packages/GitHub repos, mathematical operations.\n",
    "    5. Additional model information.\n",
    "\n",
    "    Return only a Python list with the filtered names. Do not include any additional text.\n",
    "\n",
    "    Extracted list: {extracted_names}\n",
    "\n",
    "    Provide a unique list of the remaining names.\n",
    "    \"\"\"\n",
    "\n",
    "    # Use the chat completions endpoint for the filtering step\n",
    "    filtering_response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": filtering_prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    filtered_names = extract_list_from_response(filtering_response.choices[0].message.content)\n",
    "    \n",
    "    return list(set([name.strip() for name in filtered_names if name.strip()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfdb2366-02e9-4f98-a35d-5e6ecb68d6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process the dataframe\n",
    "def process_dataframe(df, api_key):\n",
    "    df['Extracted Model Names'] = df['Solution Description'].apply(\n",
    "        lambda x: extract_and_filter_model_names(x, api_key) if pd.notna(x) else []\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "f381d0e4-9933-4063-a5c0-4eee464d7f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_empty_list(lst):\n",
    "    \"\"\"Convert a list with an empty string to an actual empty list.\"\"\"\n",
    "    if lst == [\"\"]:\n",
    "        return []\n",
    "    return lst\n",
    "    \n",
    "def calculate_metrics(df):\n",
    "    true_names = df['True Model Names']\n",
    "    extracted_names = df['Extracted Model Names']\n",
    "    \n",
    "    f1_scores = []\n",
    "    jaccard_indices = []\n",
    "    \n",
    "    for true, extracted in zip(true_names, extracted_names):\n",
    "        # Normalize both true and extracted lists\n",
    "        true_set = set(map(str.lower, normalize_empty_list(true)))\n",
    "        extracted_set = set(map(str.lower, extracted))\n",
    "        \n",
    "        # Handle the case where both sets are empty: perfect match\n",
    "        if not true_set and not extracted_set:\n",
    "            f1_scores.append(1.0)\n",
    "            jaccard_indices.append(1.0)\n",
    "            continue\n",
    "        \n",
    "        # Calculate True Positives (TP), False Positives (FP), and False Negatives (FN)\n",
    "        tp = len(true_set.intersection(extracted_set))\n",
    "        fp = len(extracted_set - true_set)\n",
    "        fn = len(true_set - extracted_set)\n",
    "        \n",
    "        # Calculate Precision, Recall, and F1 Score\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        f1_scores.append(f1)\n",
    "        \n",
    "        # Calculate Jaccard Index (Intersection over Union)\n",
    "        if len(true_set.union(extracted_set)) > 0:\n",
    "            jaccard = len(true_set.intersection(extracted_set)) / len(true_set.union(extracted_set))\n",
    "        else:\n",
    "            jaccard = 1.0  # This shouldn't be necessary now, but for safety\n",
    "        \n",
    "        jaccard_indices.append(jaccard)\n",
    "    \n",
    "    df['F1 Score'] = f1_scores\n",
    "    df['Jaccard Index'] = jaccard_indices\n",
    "    \n",
    "    # Calculate final (mean) F1 Score and Jaccard Index\n",
    "    final_f1_score = sum(f1_scores) / len(f1_scores)\n",
    "    final_jaccard_index = sum(jaccard_indices) / len(jaccard_indices)\n",
    "    \n",
    "    return df, final_f1_score, final_jaccard_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db63c659-3c63-4971-b05c-7e8daa4c3345",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8def59e-221b-47c2-aeb1-32c4e3837686",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('KaggleWinningSolutionsTraining.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac1f90be-1ea5-4d0f-8b47-d915a66e8dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, value in enumerate(data['Competition Tags']):\n",
    "    if isinstance(value, float) and np.isnan(value):\n",
    "        continue\n",
    "    else:\n",
    "        data['Competition Tags'][i] = value.split(', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8a6730-5117-44ac-b3cd-ec4578f81aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 95:5 train/test split\n",
    "train_data, test_data = train_test_split(data, test_size=0.05, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ca3578-a8d8-477c-80e2-bbdfdf941887",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv('kaggleWinningSolutionsTraining.csv', index=False)\n",
    "test_data.to_excel('kaggleWinningSolutionsTesting.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "7b2bc674-740c-4328-a99b-101233b27b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = pd.read_excel('KaggleWinningSolutionsTesting.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078f9292-8ad8-4111-90cb-e94f5478c667",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f34bd76-fc0a-4a95-acd2-11a6528149b5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Useless Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecaf40e6-abde-4498-b9a1-3c4f609e3784",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Pre-trained Models with Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50372066-87ea-4ce5-80dd-fdd7af98691b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress logging warnings\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "\n",
    "# Check if a GPU is available\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "# Load pre-trained NER model with device parameter\n",
    "ner_model = pipeline(\"ner\", model=\"dbmdz/bert-large-cased-finetuned-conll03-english\", device=device)\n",
    "text = data['Solution Description'][0]\n",
    "\n",
    "# Perform NER\n",
    "entities = ner_model(text)\n",
    "\n",
    "# Extract model names\n",
    "model_names = [entity['word'] for entity in entities if entity['entity'] in ['MODEL', 'ORG']] # 'ORG' can sometimes capture model names\n",
    "model_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d28948-ca87-4400-82a3-8dcec993525f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### KeyBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5167c3a6-4d1b-4dc0-b06e-578630809352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load KeyBERT model\n",
    "kw_model = KeyBERT()\n",
    "text = data['Solution Description'][2]\n",
    "\n",
    "# Extract keywords\n",
    "keywords = kw_model.extract_keywords(text, keyphrase_ngram_range=(1, 2), stop_words=None)\n",
    "keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de746050-651c-41f0-b74d-4fdbd3c8dd68",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Text Similarity and Clustering (Spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6bb8ab-5dc2-449d-a874-5cde2482e5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Spacy model\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# Define a list of known ML models\n",
    "known_models = [\n",
    "    \"LightGBM\", \"XGBoost\", \"CatBoost\", \"Random Forest\", \"SVM\", \"Naive Bayes\",\n",
    "    \"KNN\", \"Logistic Regression\", \"Gradient Boosting\", \"Neural Network\", \"LSTM\", \"GRU\"\n",
    "]\n",
    "\n",
    "# Get embeddings for known models\n",
    "known_model_vectors = np.array([nlp(model).vector for model in known_models])\n",
    "\n",
    "# Sample text\n",
    "text = data['Solution Description'][0]\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Extract potential model names based on similarity\n",
    "potential_models = []\n",
    "for token in doc:\n",
    "    if token.has_vector:\n",
    "        similarity = cosine_similarity([token.vector], known_model_vectors).max()\n",
    "        if similarity > 0.6:  # You can adjust the threshold\n",
    "            potential_models.append(token.text)\n",
    "\n",
    "print(\"Potential model names:\", set(potential_models))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f989e3-da12-4573-80ac-2ed33c4f543c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## ChatGPT API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e9ab5c-c5bb-417b-9134-a00a88766d3f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Main Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "880a9bd9-c095-44bd-8236-85a5abe68d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = load_api_key()\n",
    "\n",
    "df = process_dataframe(data, api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "88289277-49cb-4c83-a7c1-2a442de14a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('kaggleWinningSolutionsExtracted.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72468223-0df9-4d86-b39f-3f7262f6927a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Testing Set F1 Score & Jaccard Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "6c2c5d05-7610-4908-85d3-31861f0b3cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, value in enumerate(testdata['True Model Names']):\n",
    "    if isinstance(value, float) and np.isnan(value):\n",
    "        continue\n",
    "    else:\n",
    "        testdata['True Model Names'][i] = value.replace('\"', '').replace('[', '').replace(']', '').strip(' ').split(', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "66728602-fd50-4bdd-ae34-61a66416e95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = process_dataframe(testdata, api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "b692c750-e8d8-443b-878a-e9d511361257",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_excel('kaggleWinningSolutionsTestingExtracted.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "ba38d9d4-edcc-4b38-9571-4b9b1b602dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_excel('kaggleWinningSolutionsTestingExtracted.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "5bb1a9e7-2301-4322-812e-eb4a22b82c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final F1 Score: 0.85\n",
      "Final Jaccard Index: 0.78\n"
     ]
    }
   ],
   "source": [
    "testset_with_metrics, final_f1_score, final_jaccard_index = calculate_metrics(df_test)\n",
    "\n",
    "testset_with_metrics.head()\n",
    "print(f\"Final F1 Score: {round(final_f1_score, 2)}\")\n",
    "print(f\"Final Jaccard Index: {round(final_jaccard_index, 2)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
