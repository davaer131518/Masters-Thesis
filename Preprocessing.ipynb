{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99f4149f-5bcd-4823-8a0b-69401e3fdcce",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ef3c2516-eada-466c-9e03-894e2a8eb3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import ast\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm.notebook import tqdm\n",
    "from fake_useragent import UserAgent\n",
    "from datetime import datetime\n",
    "import time as t\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options \n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd38c117-0f53-4565-90f1-b836dbef2034",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "3856af8c-52f0-4fdc-b565-6aa635625d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read the API key from a text file\n",
    "def load_api_key(file_path='api_key.txt'):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return file.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09746763-ccd5-4f8a-9cce-b433dbef011a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(A):\n",
    "    rt = []\n",
    "    for i in A:\n",
    "        if isinstance(i,list): rt.extend(flatten(i))\n",
    "        else: rt.append(i)\n",
    "    return rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "b6824d41-7cdb-4d80-9c7c-0c406f271c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_list_from_response(response_content):\n",
    "    \"\"\"\n",
    "    This helper function processes the response content to extract the actual Python list.\n",
    "    It removes any extraneous backticks and code block markers, and then safely evaluates\n",
    "    the content to return the list.\n",
    "    \"\"\"\n",
    "    # Remove code block markers and extraneous characters\n",
    "    cleaned_content = [line for line in response_content.splitlines() if line.startswith('[') and line.endswith(']')]\n",
    "    \n",
    "    if cleaned_content:\n",
    "        try:\n",
    "            # Safely evaluate the cleaned content as a Python list\n",
    "            return ast.literal_eval(cleaned_content[0])\n",
    "        except (SyntaxError, ValueError):\n",
    "            return []\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1004,
   "id": "87bb35d3-39a4-4bb1-8299-85f540fdf74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process the dataframe\n",
    "def process_dataframe(df, api_key, chatgptfunction, NewColNameStr, UseColNameStr):\n",
    "    def process_list(x):\n",
    "        try:\n",
    "            if x != [''] or np.isnan(x):\n",
    "                return chatgptfunction(x, api_key)\n",
    "            else:\n",
    "                return []\n",
    "        except:\n",
    "            if x != ['']:\n",
    "                return chatgptfunction(x, api_key)\n",
    "            else:\n",
    "                return []\n",
    "\n",
    "    df[NewColNameStr] = df[UseColNameStr].apply(process_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "78f42789-e32e-4aac-b543-644c527dd411",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_list_from_response(response_content):\n",
    "    \"\"\"\n",
    "    This helper function processes the response content to extract the actual Python list.\n",
    "    It removes any extraneous backticks and code block markers, and then safely evaluates\n",
    "    the content to return the list.\n",
    "    \"\"\"\n",
    "    # Remove code block markers and extraneous characters\n",
    "    cleaned_content = [line for line in response_content.splitlines() if line.startswith('[') and line.endswith(']')]\n",
    "    \n",
    "    if cleaned_content:\n",
    "        try:\n",
    "            # Safely evaluate the cleaned content as a Python list\n",
    "            return ast.literal_eval(cleaned_content[0])\n",
    "        except (SyntaxError, ValueError):\n",
    "            return []\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "5c9f14da-631b-46ed-ba84-435135f3f4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to standardize model names\n",
    "def standardize_and_generalize_model_names(model_list, api_key):\n",
    "    openai.api_key = api_key\n",
    "\n",
    "    if model_list == ['']:\n",
    "        return []\n",
    "\n",
    "    standardization_prompt = f\"\"\"\n",
    "    Standardize the following list of machine learning and deep learning model names according to the following rules:\n",
    "    1. Standardize variations of the same model to a single form. Make sure short forms of model names are changed into long form (e.g., 'xgb' and 'XGBoost' should both be 'xgboost', 'CatBoost' and 'CB' should be 'catboost', LGBM should be lightgbm, etc.).\n",
    "    2. For deep learning architectures, keep only the base architecture name (e.g., ResNet18 and ResNet50 should both be resnet).\n",
    "    3. For general architecture types, simplify to the basic form (e.g., '2D CNN' and '3D CNN' should be 'cnn', '2D Unet' should be 'unet', rnn model should be rnn, etc.).\n",
    "    4. Remove duplicates, ensuring each model name appears only once.\n",
    "\n",
    "    List: {str(model_list)}\n",
    "\n",
    "    Return only a final unique Python list of the model names.\n",
    "    \"\"\"\n",
    "\n",
    "    # Use the chat completions endpoint for the filtering step\n",
    "    generalizing_response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": standardization_prompt}\n",
    "        ]\n",
    "    )\n",
    "    generalized_names = extract_list_from_response(generalizing_response.choices[0].message.content)\n",
    "    \n",
    "    return list(set([name.strip() for name in generalized_names if name.strip()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "id": "272c4df5-354c-477b-9beb-83edb37fad44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to standardize model names\n",
    "def filter_models(model_list, api_key):\n",
    "    openai.api_key = api_key\n",
    "\n",
    "    if model_list == ['']:\n",
    "        return []\n",
    "\n",
    "    filtering_prompt = f\"\"\"\n",
    "    Filter the following list of machine learning (ML) and deep learning (DL) model and method names according to the following rules:\n",
    "    1. Remove anything none ML or DL related (e.g. Python package and library names, as well as operations such as pairwise ranking, or smoothing)\n",
    "    2. Remove things like paths, usernames for websites, etc.\n",
    "    3. Remove anything very general such as the 'deep learning', or machine learning.\n",
    "    3. Do not remove things such as names of language models, DL models and architecture types.\n",
    "\n",
    "    List: {str(model_list)}\n",
    "\n",
    "    Keep the remaining elements of the list with the exactlty as they were originally. Return only a final Python list containing the filtered elements.\n",
    "    \"\"\"\n",
    "\n",
    "    # Use the chat completions endpoint for the filtering step\n",
    "    filtering_response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": filtering_prompt}\n",
    "        ]\n",
    "    )\n",
    "    filtered_names = extract_list_from_response(filtering_response.choices[0].message.content)\n",
    "    \n",
    "    return list(set([name.strip() for name in filtered_names if name.strip()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 954,
   "id": "998d5363-d752-47db-b609-4006f1390ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean competition tags\n",
    "def clean_tags(tag_list, api_key):\n",
    "    openai.api_key = api_key\n",
    "    if tag_list == ['']:\n",
    "        return []\n",
    "\n",
    "    cleaning_prompt = f\"\"\"\n",
    "    Clean the following list of machine learning (ML) and deep learning (DL) task tags according to the following rules:\n",
    "    1. Remove anything none ML or DL task related.\n",
    "    2. Remove names of general fields such as education, sports, mathematics, robotics, etc. as they are not task specific (task specific examples are e.g image classification).\n",
    "    3. Standardize the names of the tags into a simple form if neccesary.\n",
    "    4. If neccessary, merge two tags into one (e.g 'image', 'classification' can be 'image classification').\n",
    "    5. General ML fields such as computer vision or classical machine learning are fine.\n",
    "\n",
    "    List: {str(tag_list)}\n",
    "\n",
    "    Return only a final Python list without duplicates containing the cleaned tags.\n",
    "    \"\"\"\n",
    "\n",
    "    # Use the chat completions endpoint for the filtering step\n",
    "    cleaning_response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": cleaning_prompt}\n",
    "        ]\n",
    "    )\n",
    "    cleaned_names = extract_list_from_response(cleaning_response.choices[0].message.content)\n",
    "    \n",
    "    return list(set([name.strip() for name in cleaned_names if name.strip()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1060,
   "id": "dd5947a3-af88-4a2a-a4fe-4ada268cbf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to group models hierarchically \n",
    "def group_models(mod_list, api_key):\n",
    "    openai.api_key = api_key\n",
    "    if mod_list == ['']:\n",
    "        return []\n",
    "\n",
    "    grouping_prompt = f\"\"\"\n",
    "   Given the following list of machine learning (ML) and deep learning (DL) models/architectures, categorize each model into its broader category or type. For example, if the model is 'efficientnet,' categorize it under 'cnn'. If the model is 'xgboost,' or 'catboost', 'lightgbm' categorize it under 'boosting', etc. For cases where a given model is a classical ML model and no specific category exists for it, you can label it as 'classical ml'. Similarly, group all models based on their broader ML/DL category.\n",
    "\n",
    "    List: {str(mod_list)}\n",
    "\n",
    "    Return only a final Python list without duplicates containing the broader category/types of the models within the list.\n",
    "    \"\"\"\n",
    "\n",
    "    # Use the chat completions endpoint for the filtering step\n",
    "    grouping_response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": grouping_prompt}\n",
    "        ]\n",
    "    )\n",
    "    grouped_names = extract_list_from_response(grouping_response.choices[0].message.content)\n",
    "    \n",
    "    return list(set([name.strip() for name in grouped_names if name.strip()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a50f640-843b-45a0-83e1-a5d22d3d34bd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6bb941-bf75-43d6-8f67-a84f0cb91e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = load_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "7a9e4696-1b7f-4b05-90fb-43ca4969f5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('kaggleWinningSolutionsExtracted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "3d2d334c-3526-4a4d-877c-2030d7028015",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, value in enumerate(data['Extracted Model Names']):\n",
    "    if isinstance(value, float) and np.isnan(value):\n",
    "        continue\n",
    "    else:\n",
    "        data['Extracted Model Names'][i] = value.replace('[', '').replace(']', '').replace('\\'', '').strip(' ').split(', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3c22c4-9178-4fb4-8a9d-215f1a02b84e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Standardize Model Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "b5bcb7cc-76bd-42d5-92e7-dffeeaf2dd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = process_dataframe(data, api_key, standardize_and_generalize_model_names, 'Generalized Model Names', 'Extracted Model Names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "9de1cce7-ae2e-44ce-a91a-42def53f381d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('kaggleWinningSolutionsGeneralized.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f51863-1f6b-4c61-a626-260a3535a165",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Filter Noise from Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "3072315a-071d-4316-b17a-80d9c86221d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('kaggleWinningSolutionsGeneralized.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "id": "12931ffe-c162-4277-80d0-d7a12799f38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = process_dataframe(data, api_key, filter_models, 'Filtered Generalized Model Names', 'Generalized Model Names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "id": "a1701751-80c2-45f1-a8bc-3b65de60ba8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('kaggleWinningSolutionsGeneralized.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a061ce3-4528-406d-8bc1-2994221e37d5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Clean Competition Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "id": "4135c042-1cf4-4f84-8aab-f1cd39314f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('kaggleWinningSolutionsGeneralized.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "id": "650639ba-3361-4395-9af8-68e67b53fda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, value in enumerate(data['Competition Tags']):\n",
    "    if isinstance(value, float) and np.isnan(value):\n",
    "        continue\n",
    "    else:\n",
    "        data['Competition Tags'][i] = value.replace('[', '').replace(']', '').replace('\"', '').replace('\\'', '').split(', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 964,
   "id": "03057607-9cbf-4ba8-b2d6-2524fdc2c09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = process_dataframe(data, api_key, clean_tags, 'Clean Competition Tags', 'Competition Tags')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 968,
   "id": "8962c16e-bf3b-406c-a1a1-4363014c6e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('kaggleWinningSolutionsGeneralized.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d654a795-b8de-433d-b435-e0c6232ab0bb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Categorize Models Hierarchically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 971,
   "id": "8d80f2c6-360d-42e7-9265-410bd8a0f8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('kaggleWinningSolutionsGeneralized.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 988,
   "id": "77dc63fa-84f9-4912-8991-97c112d147b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, value in enumerate(data['Filtered Generalized Model Names']):\n",
    "    if isinstance(value, float) and np.isnan(value):\n",
    "        continue\n",
    "    else:\n",
    "        data['Filtered Generalized Model Names'][i] = value.replace('[', '').replace(']', '').replace('\\'', '').strip(' ').split(', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1068,
   "id": "a37d16ea-f9e6-4ff7-9b0c-f963ae8c421e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = process_dataframe(data, api_key, group_models, 'Broader Hierarchical Group', 'Filtered Generalized Model Names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1070,
   "id": "c7ac9e04-e513-48e9-b36a-1b5cf8970b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('kaggleWinningSolutionsGeneralized.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6e5e82-6900-45fd-b022-39cc81d809d2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Scrape Timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46669c0f-0897-40c2-bcd3-a1a92440c1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('kaggleWinningSolutionsGeneralized.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1e6ff7eb-1a47-4332-a052-e11664c00f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "ua = UserAgent()\n",
    "options = Options()\n",
    "options.add_argument(\"--incognito\")\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument('--disable-blink-features=AutomationControlled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5a0a899d-30e3-491d-b2f6-916569956db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The chromedriver version (127.0.6533.72) detected in PATH at C:\\chromedriver.exe might not be compatible with the detected chrome version (128.0.6613.113); currently, chromedriver 128.0.6613.86 is recommended for chrome 128.*, so it is advised to delete the driver in PATH and retry\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2752c7a9d8ed4a7c8713cad569e8dc00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2613 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dictionary to store unique links and their corresponding dates\n",
    "unique_links_dates = {}\n",
    "\n",
    "browser = webdriver.Chrome(options=options)  \n",
    "for link in tqdm(data['Competition Link']): \n",
    "    # Check if the link has already been processed\n",
    "    if link in unique_links_dates:\n",
    "        continue \n",
    "\n",
    "    browser.get(link)\n",
    "    t.sleep(1)\n",
    "    source = browser.page_source\n",
    "    soup = BeautifulSoup(source, 'html.parser')\n",
    "\n",
    "    test_date = soup.find('div', {'class':'sc-dxmpTp evmcxM'})\n",
    "    if test_date:\n",
    "        date_container = test_date.find_all('span', {'class':'sc-bSlUec bdWnNi'})\n",
    "        date_raw = date_container[-1].text.strip()\n",
    "        date_obj = datetime.strptime(date_raw, '%b %d, %Y')\n",
    "        date = date_obj.strftime('%d-%m-%Y')\n",
    "        unique_links_dates[link] = date  # Store the link and date in the dictionary\n",
    "    else:\n",
    "        unique_links_dates[link] = None  # Store None if the date is not found\n",
    "\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "242e9040-45d6-4520-abe5-45054196341c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Date'] = data['Competition Link'].map(unique_links_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0b7ad3c8-c51e-4c12-9da0-c1385ff4f4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_excel('kaggleWinningSolutionsGeneralized.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
