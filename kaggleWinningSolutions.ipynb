{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f505c3cd-5dd2-4279-b77f-c466f1627625",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2f4b3ef-3c53-4e10-a63e-08b0a9a69b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import os\n",
    "import random\n",
    "import time as t\n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "from fake_useragent import UserAgent\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from stem import Signal\n",
    "from stem.control import Controller\n",
    "from subprocess import Popen, PIPE\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options \n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from IPython.core.display import HTML\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c171b6-e9f3-49c0-acd0-3f54b592ad7f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3f4044d-ba7f-4032-9729-e5be77253c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(A):\n",
    "    rt = []\n",
    "    for i in A:\n",
    "        if isinstance(i,list): rt.extend(flatten(i))\n",
    "        else: rt.append(i)\n",
    "    return rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5c59268-f9ea-42b0-9e02-3b8ec72f0709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniquize(seq):\n",
    "    seen = set()\n",
    "    seen_add = seen.add\n",
    "    return [x for x in seq if not (x in seen or seen_add(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "760a5b99-9f75-4e23-b7a2-d6bec20b087f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tor_path = r'C:\\Users\\david\\Desktop\\Tor Browser\\Browser\\TorBrowser\\Tor\\tor.exe'\n",
    "chrome_driver_path = r'C:\\chromedriver.exe'\n",
    "socks_port = 9052\n",
    "control_port = 9051\n",
    "\n",
    "def start_tor():    \n",
    "    torrc_content = f'''\n",
    "    SocksPort {socks_port}\n",
    "    ControlPort {control_port}\n",
    "    CookieAuthentication 0\n",
    "    '''\n",
    "    with open('torrc.tmp', 'w') as f:\n",
    "        f.write(torrc_content)\n",
    "    \n",
    "    tor_command = f'\"{tor_path}\" -f torrc.tmp'\n",
    "    tor_process = Popen(tor_command, stdout=PIPE, stderr=PIPE, shell=True)\n",
    "    t.sleep(1) \n",
    "    return tor_process\n",
    "    \n",
    "def stop_tor(tor_process):\n",
    "    if tor_process:\n",
    "        tor_process.terminate()\n",
    "        tor_process.wait()\n",
    "\n",
    "def change_tor_identity():\n",
    "    try:\n",
    "        with Controller.from_port(port=control_port) as controller:\n",
    "            controller.authenticate()  # no authentication required with CookieAuthentication 0\n",
    "            controller.signal(Signal.NEWNYM)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to change Tor identity: {e}\")\n",
    "\n",
    "def create_browser():\n",
    "    PROXY = f\"socks5://localhost:{socks_port}\"\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--proxy-server=%s' % PROXY)\n",
    "    # options.add_argument('--headless')\n",
    "    # options.add_argument('--disable-gpu')\n",
    "    # options.add_argument('--no-sandbox')\n",
    "    \n",
    "    service = Service(executable_path=chrome_driver_path)\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e696ca23-17c5-467b-969c-e8ac7c7af66f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Generate and Scrape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375700bb-2faf-46ba-a784-d8fd10750f46",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Generate Data via Meta Kaggle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03e08b4-c20c-417a-ad88-63f052745ce6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_path = \"./\"  \n",
    "\n",
    "competitions_df = pd.read_csv(data_path + \"Competitions.csv\")\n",
    "comps_to_use = [\"Featured\", \"Research\", \"Recruitment\"]\n",
    "competitions_df = competitions_df[competitions_df[\"HostSegmentTitle\"].isin(comps_to_use)]\n",
    "competitions_df[\"EnabledDate\"] = pd.to_datetime(competitions_df[\"EnabledDate\"], format=\"%m/%d/%Y %H:%M:%S\")\n",
    "competitions_df = competitions_df.sort_values(by=\"EnabledDate\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "forum_topics_df = pd.read_csv(data_path + \"ForumTopics.csv\")\n",
    "comp_tags_df = pd.read_csv(data_path + \"CompetitionTags.csv\")\n",
    "tags_df = pd.read_csv(data_path + \"Tags.csv\", usecols=[\"Id\", \"Name\"])\n",
    "\n",
    "def get_comp_tags(comp_id):\n",
    "    temp_df = comp_tags_df[comp_tags_df[\"CompetitionId\"] == comp_id]\n",
    "    temp_df = pd.merge(temp_df, tags_df, left_on=\"TagId\", right_on=\"Id\")\n",
    "    tags_str = \"Tags : \"\n",
    "    for _, row in temp_df.iterrows():\n",
    "        tags_str += row[\"Name\"] + \", \"\n",
    "    return tags_str.strip(\", \")\n",
    "\n",
    "def check_solution(topic):\n",
    "    is_solution = False\n",
    "    to_exclude = [\"?\", \"submit\", \"why\", \"what\", \"resolution\", \"benchmark\"]\n",
    "    if \"solution\" in topic.lower():\n",
    "        is_solution = True\n",
    "        for exc in to_exclude:\n",
    "            if exc in topic.lower():\n",
    "                is_solution = False\n",
    "    to_include = [\"2nd place code\", '\"dance with ensemble\" sharing']\n",
    "    for inc in to_include:\n",
    "        if inc in topic.lower():\n",
    "            is_solution = True\n",
    "    return is_solution\n",
    "\n",
    "def get_discussion_results(forum_id, n):\n",
    "    results_df = forum_topics_df[forum_topics_df[\"ForumId\"] == forum_id]\n",
    "    results_df[\"is_solution\"] = results_df[\"Title\"].apply(lambda x: check_solution(str(x)))\n",
    "    results_df = results_df[results_df[\"is_solution\"] == 1]\n",
    "    results_df = results_df.sort_values(by=[\"Score\", \"TotalMessages\"], ascending=False).head(n).reset_index(drop=True)\n",
    "    return results_df[[\"Title\", \"Id\", \"Score\", \"TotalMessages\", \"TotalReplies\"]]\n",
    "\n",
    "def render_html_for_comp(forum_id, comp_id, comp_name, comp_slug, comp_subtitle, n):\n",
    "    results_df = get_discussion_results(forum_id, n)\n",
    "    \n",
    "    if len(results_df) < 1:\n",
    "        return\n",
    "    \n",
    "    comp_tags = get_comp_tags(comp_id)\n",
    "    \n",
    "    comp_url = \"https://www.kaggle.com/c/\" + str(comp_slug)\n",
    "    hs = f\"\"\"\n",
    "        <style>\n",
    "            .rendered_html tr {{font-size: 12px; text-align: left;}}\n",
    "            th {{\n",
    "                text-align: left;\n",
    "            }}\n",
    "        </style>\n",
    "        <h3><font color=\"#1768ea\"><a href=\"{comp_url}\">{comp_name}</font></h3>\n",
    "        <p>{comp_subtitle}</p>\n",
    "    \"\"\"\n",
    "    \n",
    "    if comp_tags != \"Tags :\":\n",
    "        hs += f\"\"\"\n",
    "            <p>{comp_tags}</p>\n",
    "        \"\"\"\n",
    "    \n",
    "    hs += \"\"\"\n",
    "        <table>\n",
    "        <tr>\n",
    "            <th><b>S.No</b></th>\n",
    "            <th><b>Discussion Title</b></th>\n",
    "            <th><b>Number of upvotes</b></th>\n",
    "            <th><b>Total Replies</b></th>\n",
    "        </tr>\"\"\"\n",
    "    \n",
    "    for i, row in results_df.iterrows():\n",
    "        url = f\"https://www.kaggle.com/c/{comp_slug}/discussion/{row['Id']}\"\n",
    "        hs += f\"\"\"\n",
    "            <tr>\n",
    "                <td>{i+1}</td>\n",
    "                <td><a href=\"{url}\" target=\"_blank\"><b>{row['Title']}</b></a></td>\n",
    "                <td>{row['Score']}</td>\n",
    "                <td>{row['TotalReplies']}</td>\n",
    "            </tr>\"\"\"\n",
    "    hs += \"</table>\"\n",
    "    display(HTML(hs))\n",
    "    \n",
    "    return hs  # Return the HTML string\n",
    "\n",
    "# Collect the rendered HTML in a list\n",
    "html_list = []\n",
    "\n",
    "for _, comp_row in competitions_df.iterrows():\n",
    "    html_string = render_html_for_comp(comp_row[\"ForumId\"], comp_row[\"Id\"], comp_row[\"Title\"], comp_row[\"Slug\"], comp_row[\"Subtitle\"], 12)\n",
    "    if html_string:\n",
    "        html_list.append(html_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2f1206-2662-49a8-8cfd-a1f112369964",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Save Generated HTML as Website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dcc5e3-851b-4b18-bc3d-925674f483ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the HTML strings into a single HTML document\n",
    "full_html = \"<html><body>\" + \"\".join(html_list) + \"</body></html>\"\n",
    "\n",
    "# Save the HTML to a file\n",
    "with open(\"kaggle_winning_solutions.html\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(full_html)\n",
    "\n",
    "print(\"HTML file saved. You can now open 'kaggle_winning_solutions.html' in your web browser to inspect the content.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064eaf29-0e03-45ba-8fe2-de1939f0d4ca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Parse Website & Scrape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4980915-229b-41c8-bc97-0364ccbf7e08",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Data Part 1 (Competitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02c417ac-0bab-4ae6-bae9-6665590a1e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the HTML file content\n",
    "with open(\"kaggle_winning_solutions.html\", \"r\", encoding=\"utf-8\") as file:\n",
    "    html_content = file.read()\n",
    "\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Extract competition titles\n",
    "competition_titles_raw = soup.find_all('h3')\n",
    "competition_titles = [i.text for i in competition_titles_raw]\n",
    "competition_links = [i.find('a', {'href':True})['href'] for i in competition_titles_raw]\n",
    "\n",
    "# Extract short descriptions for competitions\n",
    "details_container = []\n",
    "for h3 in competition_titles_raw:\n",
    "    next_p_tag = h3.find_next('p')\n",
    "    if next_p_tag:\n",
    "        details_container.append(next_p_tag)\n",
    "        \n",
    "details_small = [i.text for i in details_container]\n",
    "\n",
    "# Extract competition tags\n",
    "tags_container = []\n",
    "for h3 in competition_titles_raw:\n",
    "    p_tags = []\n",
    "    next_sibling = h3.find_next_sibling()\n",
    "    while next_sibling and len(p_tags) < 2:\n",
    "        if next_sibling.name == 'p':\n",
    "            p_tags.append(next_sibling)\n",
    "        next_sibling = next_sibling.find_next_sibling()\n",
    "    \n",
    "    if len(p_tags) == 2:\n",
    "        tags_container.append(p_tags[1])\n",
    "    else:\n",
    "        tags_container.append(None)\n",
    "\n",
    "for i, p_tag in enumerate(tags_container):\n",
    "    if p_tag and 'Tags' not in p_tag.text:\n",
    "        tags_container[i] = None\n",
    "\n",
    "for i, tag in enumerate(tags_container):\n",
    "    if tag is not None:\n",
    "        tags_container[i] = tag.text.replace('Tags : ', '')\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "# Extract solutions\n",
    "solutions_container = soup.find_all('table')\n",
    "solutions_raw = [i.find_all('tr')[1:] for i in solutions_container]\n",
    "\n",
    "# Store data extracted so far in dataframe\n",
    "all_competition_links = []\n",
    "all_competition_titles = []\n",
    "all_details_small = []\n",
    "all_tags = []\n",
    "all_solution_links = []\n",
    "for i, competition in enumerate(solutions_raw):\n",
    "    solution_links = [i.find('a', {'href':True})['href'] for i in competition]\n",
    "    for j in range(len(solution_links)):\n",
    "        all_competition_titles.append(competition_titles[i])\n",
    "        all_details_small.append(details_small[i])\n",
    "        all_tags.append(tags_container[i])\n",
    "        all_competition_links.append(competition_links[i])\n",
    "        \n",
    "    all_solution_links.append(solution_links)\n",
    "    \n",
    "all_solution_links = flatten(all_solution_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1ae41cb-14cc-47b6-9e98-d5bfbe1f7913",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "df['Competition Link'] = all_competition_links\n",
    "df['Competition Title'] = all_competition_titles\n",
    "df['Competition Short Description'] = all_details_small\n",
    "df['Competition Tags'] = all_tags\n",
    "df['Winning Solution Links'] = all_solution_links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f62230-d524-438f-b195-b6d5e79c9783",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Data Part 2 (Competitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "69d6d2ab-2e38-40b2-8474-72f48cbc2987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63b90612abea461592c8fb23b0ef8a56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2751 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>Cleanup completed.</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ensure any previous Tor processes are terminated\n",
    "os.system(\"taskkill /f /im tor.exe\")\n",
    "\n",
    "all_overviews = []\n",
    "all_data = []\n",
    "previous_link = None\n",
    "max_retries = 300  \n",
    "\n",
    "tor_process = start_tor()\n",
    "change_tor_identity()\n",
    "browser = create_browser()\n",
    "\n",
    "progress_bar = tqdm(all_competition_links)\n",
    "log_display = display(HTML(\"\"), display_id=True)\n",
    "for index, link in enumerate(progress_bar):\n",
    "    log_display.update(HTML(\"\"))\n",
    "    retries = 0\n",
    "    success = False\n",
    "    while retries < max_retries and not success:\n",
    "        try:\n",
    "            if link == previous_link:\n",
    "                all_overviews.append(overview)\n",
    "                all_data.append(data)\n",
    "                success = True\n",
    "            else:\n",
    "                browser.get(link)\n",
    "                t.sleep(3)\n",
    "                source = browser.page_source\n",
    "                soup = BeautifulSoup(source, 'html.parser')\n",
    "\n",
    "                test_page = soup.find('div', {'class': 'sc-kpdYNm bUTszs'})\n",
    "                if test_page:                \n",
    "                    test_overview = soup.find('div', {'class': 'sc-gZPpYW YYkRx'})\n",
    "                    if test_overview:\n",
    "                        overview_raw = test_overview.find_all('p')\n",
    "                        overview = [i.text.replace('\\n', '').replace('\\u200b', '') for i in overview_raw]\n",
    "                        overview = ' '.join(overview)\n",
    "                        all_overviews.append(overview)\n",
    "                    else:\n",
    "                        overview = None\n",
    "                        all_overviews.append(overview)\n",
    "                        \n",
    "                    browser.get(link + '/data')\n",
    "                    t.sleep(3)\n",
    "                    source = browser.page_source\n",
    "                    soup = BeautifulSoup(source, 'html.parser')\n",
    "                    \n",
    "                    test_data = soup.find('div', {'class': 'sc-ldJDQK inGMtK'})\n",
    "                    if test_data:\n",
    "                        test_ptag = test_data.find_all('p') \n",
    "                        if test_ptag:\n",
    "                            data_narrow = test_ptag \n",
    "                            data_raw = [i.text.replace('\\n', '').replace('\\u200b', '') for i in data_narrow]\n",
    "                            data = '. '.join(data_raw)\n",
    "                            all_data.append(data)\n",
    "                        else:\n",
    "                            data_narrow = test_data.find_all('div')\n",
    "                            data_raw = [i.text.replace('\\n', '').replace('\\u200b', '') for i in data_narrow]\n",
    "                            data = '. '.join(data_raw)\n",
    "                            all_data.append(data)\n",
    "                    else:\n",
    "                        data = None\n",
    "                        all_data.append(data)\n",
    "                    \n",
    "                    previous_link = link\n",
    "                    success = True \n",
    "                else:\n",
    "                    raise ValueError(f'Error processing link {link} at index {index}')\n",
    "        except:\n",
    "            log_display.update(HTML(f\"<p>Error processing link {link}</p>\"))\n",
    "            retries += 1\n",
    "            if retries < max_retries:\n",
    "                log_display.update(HTML(f\"<p>Retrying with a new IP address... retry number {retries}</p>\"))\n",
    "                browser.quit()\n",
    "                t.sleep(0.5)\n",
    "                stop_tor(tor_process)\n",
    "                os.system(\"taskkill /f /im tor.exe\")\n",
    "                tor_process = start_tor()\n",
    "                change_tor_identity()\n",
    "                browser = create_browser()\n",
    "            else:\n",
    "                log_display.update(HTML(\"<p>Max retries reached. Moving to next link.</p>\"))\n",
    "\n",
    "browser.quit()\n",
    "stop_tor(tor_process)\n",
    "os.remove('torrc')\n",
    "log_display.update(HTML(\"<p>Cleanup completed.</p>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ec0d8c-d010-4a0d-9dbe-4a034bd3f1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Competition Extended Description'] = all_overviews\n",
    "df['Competition Data Description'] = all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485a5921-a76f-4a82-bdb8-a5fc6d04a28a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Data Part 3 (Solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7ecdc3b1-8e7c-4770-bbbc-87a20a495798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cdaffbccd3440cf8e693e27b9d179ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/638 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>Cleanup completed.</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ensure any previous Tor processes are terminated\n",
    "os.system(\"taskkill /f /im tor.exe\")\n",
    "\n",
    "all_solutions = []\n",
    "all_images = []\n",
    "all_urls = []\n",
    "\n",
    "progress_bar = tqdm(list(df['Winning Solution Links'].values))\n",
    "log_display = display(HTML(\"\"), display_id=True)\n",
    "batch_size = 300\n",
    "\n",
    "for i, solution in enumerate(progress_bar):\n",
    "    log_display.update(HTML(\"\"))\n",
    "    if i % batch_size == 0:\n",
    "        if i != 0:\n",
    "            browser.quit()\n",
    "            stop_tor(tor_process)\n",
    "            os.system(\"taskkill /f /im tor.exe\")\n",
    "            \n",
    "        tor_process = start_tor()\n",
    "        change_tor_identity()\n",
    "        browser = create_browser()\n",
    "\n",
    "    retries = 0\n",
    "    success = False\n",
    "    while retries < max_retries and not success:\n",
    "        try:\n",
    "            browser.get(solution)\n",
    "            t.sleep(random.randint(5, 10))  # Randomize sleep time\n",
    "            source = browser.page_source\n",
    "            soup = BeautifulSoup(source, 'html.parser')\n",
    "\n",
    "            test_solution = soup.find('div', {'class':'sc-fbbrMC eWoIO'})\n",
    "            if test_solution:\n",
    "                solution_container = test_solution.find_all('p')\n",
    "                solution_raw = [i.text.replace('\\n', '').replace('\\u200b', '') for i in solution_container]\n",
    "                solution = ' '.join(solution_raw)\n",
    "                all_solutions.append(solution)\n",
    "\n",
    "                test_image = test_solution.find('img')\n",
    "                if test_image:\n",
    "                    image = True\n",
    "                    all_images.append(image)\n",
    "                else:\n",
    "                    image = False\n",
    "                    all_images.append(image)\n",
    "\n",
    "                test_urls = test_solution.find('a', {'href': True})\n",
    "                if test_urls:\n",
    "                    urls_raw = test_solution.find_all('a', {'href': True})\n",
    "                    urls = [i['href'] for i in urls_raw]\n",
    "                    all_urls.append(urls)\n",
    "                else:\n",
    "                    urls = None\n",
    "                    all_urls.append(urls)\n",
    "                success = True\n",
    "            else:\n",
    "                raise ValueError(f'Problem at iteration: {i}')\n",
    "\n",
    "        except Exception as e:\n",
    "            log_display.update(HTML(f\"<p>Error processing solution {solution}: {e}</p>\"))\n",
    "            retries += 1\n",
    "            if retries < max_retries:\n",
    "                log_display.update(HTML(f\"<p>Retrying with a new IP address... retry number {retries}</p>\"))\n",
    "                browser.quit()\n",
    "                t.sleep(0.5)\n",
    "                stop_tor(tor_process)\n",
    "                os.system(\"taskkill /f /im tor.exe\")\n",
    "                tor_process = start_tor()\n",
    "                change_tor_identity()\n",
    "                browser = create_browser()\n",
    "            else:\n",
    "                success = True\n",
    "                \n",
    "                solution = None\n",
    "                all_solutions.append(solution)\n",
    "                image = None\n",
    "                all_images.append(image)\n",
    "                urls = None\n",
    "                all_urls.append(urls)\n",
    "                log_display.update(HTML(\"<p>Max retries reached. Moving to next link.</p>\"))\n",
    "\n",
    "browser.quit()\n",
    "stop_tor(tor_process)\n",
    "os.remove('torrc')\n",
    "log_display.update(HTML(\"<p>Cleanup completed.</p>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9738be82-02d3-4a32-b48f-9dd4ca0266e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Solution Description'] = all_solutions\n",
    "df['Contains Image'] = all_images\n",
    "df['Internal Links'] = all_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56525d1c-a46e-4069-a1b6-08fc7cd2ed30",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "78316d94-fe6a-4412-b321-73ef6d093df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('kaggleWinningSolutions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
